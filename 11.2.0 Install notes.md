# Install spark and java

Installing a working Spark and/or Hadoop setup is non-trivial. You are encouraged to spend time to get at least one version working: either Bluecrystal phase 4, or a local version.

* [General overview](https://opensource.com/article/18/11/pyspark-jupyter-notebook)
* [Installation on Windows](https://naomi-fridman.medium.com/install-pyspark-to-run-on-jupyter-notebook-on-windows-4ec2009de21f)
* [Installation on Mac](https://medium.com/@roshinijohri/spark-with-jupyter-notebook-on-macos-2-0-0-and-higher-c61b971b5007)

## On Mac OSX (Big Sur)

### Install spark, and its dependencies (including java)
```
brew install apache-spark
echo 'export PATH="/opt/homebrew/opt/openjdk@11/bin:$PATH"' >> $HOME/.bash_profile
```

### Install pyspark
```
conda install pyspark
```

Now pyspark is ready to use in a notebook.

## On Bluecrystal 

Accessing spar and java is handled with **Modules**, which are described within the relevent sections. Some downloads are also required for hadoop, which provides HDFS, but this is described using a working version on BC4.

## Accessing the data and code

The basic way to access this code is via:

```{bash}
git clone https://github.com/dsbristol/pyspark.git
```

Then get started with 11.2.1.